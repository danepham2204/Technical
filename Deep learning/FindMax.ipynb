{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cuda\n",
    "#include <iostream>\n",
    "#include <climits>\n",
    "\n",
    "// 1 block = 8 warps = 256 threads\n",
    "/*\n",
    "blockIdx.x = Which Row?\n",
    "\n",
    "blockDim.x = How many seats are in one row?\n",
    "\n",
    "threadIdx.x = Which seat am I in right now?\n",
    "*/\n",
    "using namespace std;\n",
    "\n",
    "__global__ void findMax(int *arr, int *max, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (idx < n) {\n",
    "        atomicMax(max, arr[idx]);\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n = 50;\n",
    "    int a[n];\n",
    "    int maxHost = INT_MIN;\n",
    "\n",
    "    cout << \"Vector elements: \";\n",
    "     for (int i = 0; i < n; i++) {\n",
    "        a[i] = rand() % 100;\n",
    "        cout << a[i] << \" \";\n",
    "    }\n",
    "\n",
    "    cout << endl;\n",
    "    \n",
    "    int *ad, *maxd;\n",
    "\n",
    "    cudaMalloc(&ad, n * sizeof(int));\n",
    "    cudaMalloc(&maxd, sizeof(int));\n",
    "\n",
    "    // move data from a and maxHost to ad, maxD for GPU calculation \n",
    "    cudaMemcpy(ad, a, n * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(maxd, &maxHost, sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    int threads = 256;\n",
    "    int blocks = ( n + threads - 1) / threads;\n",
    "\n",
    "    findMax <<< blocks, threads >>> (ad, maxd, n);\n",
    "\n",
    "    cudaMemcpy(&maxHost, maxd, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    cout << \"Max element: \" << maxHost << endl;\n",
    "\n",
    "    cudaFree(ad);\n",
    "    cudaFree(maxd);\n",
    "\n",
    "    return 0;\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

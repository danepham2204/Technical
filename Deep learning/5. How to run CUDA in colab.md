Command:

1. !nvidia-smi: Show the current GPU infra
2. !nvcc --version: Nvidia CUDA version
3. !pip install nvcc4jupyter -> Translator for nvidia to run in colab
4. %load_ext nvcc4jupyter

```
%%cuda
#include <iostream>
#include <climits>
__global__ void naive_gemm(
    const float* __restrict__ A,
    const float* __restrict__ B,
    float* __restrict__ C,
    int M, int N, int K,
    float alpha = 1.0f,
    float beta  = 0.0f)
{
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row >= M || col >= N) return;

    float sum = 0.0f;

    #pragma unroll 4   // small hint to compiler
    for (int k = 0; k < K; k++) {
        sum += A[row * K + k] * B[k * N + col];
    }

    C[row * N + col] = alpha * sum + beta * C[row * N + col];
}

```
